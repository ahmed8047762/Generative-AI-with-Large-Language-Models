# Generative AI with Large Language Models

## Overview
This DeepLearning.AI project, "Generative AI with Large Language Models," consists of three modules designed to provide participants with foundational knowledge, practical skills, and a functional understanding of how generative AI works. Led by expert AWS AI practitioners actively involved in building and deploying AI in business use-cases, the course delves into the latest research on Generative AI to showcase its value in cutting-edge technology.

## Learning Objectives
- Gain a deep understanding of generative AI, covering key steps in the Large Language Models (LLMs) based generative AI lifecycle, from data gathering and model selection to performance evaluation and deployment.
- Explore the transformer architecture powering LLMs, their training process, and how fine-tuning enables adaptation to specific use cases.
- Utilize empirical scaling laws to optimize the model's objective function across dataset size, compute budget, and inference requirements.
- Apply state-of-the-art training, tuning, inference, tools, and deployment methods to maximize model performance within project constraints.
- Discuss challenges and opportunities that generative AI presents for businesses through insights from industry researchers and practitioners.

## Skills Developed
- Python Programming
- Machine Learning
- Large Language Models (LLMs)
- Generative AI

## Course Structure
The project consists of three modules covering fundamental aspects of generative AI and its application in real-world scenarios. Participants will develop practical intuition on leveraging generative AI technology effectively.
